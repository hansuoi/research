{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cordless-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリとloggingの設定\n",
    "import MeCab\n",
    "import argparse\n",
    "import codecs\n",
    "import evaluate\n",
    "import glove\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "\tdescription=\"Build a GloVe vector-space model from the provided corpus.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "\t'--window_size',\n",
    "    default=10,\n",
    "\ttype=int,\n",
    "    help=\"Number of context words to track to left and right of each word.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "\t'--min_count',\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help=(\"Discard cooccurrence pairs where at \"\n",
    "\t\t  \"least one of the words occurs fewer \"\n",
    "\t\t  \"than this many times in the training corpus\")\n",
    ")\n",
    "parser.add_argument(\n",
    "\t'--embedding_size',\n",
    "    default=100,\n",
    "    type=int,\n",
    "    help=\"Dimensionality of output word vectors\"\n",
    ")\n",
    "parser.add_argument(\n",
    "\t'--iterations',\n",
    "    default=25,\n",
    "    type=int,\n",
    "    help=\"Number of training iterations.\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s\\t%(message)s\")\n",
    "logger = logging.getLogger(\"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('suihanki_wakati.txt', mode='r', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "# corpus[i文目][j語目]の2次元配列を作る\n",
    "cps = []\n",
    "s = []\n",
    "w = ''\n",
    "for c in corpus:\n",
    "    if c == '\\n':\n",
    "        s.append(w)\n",
    "        w = ''\n",
    "        cps.append(s)\n",
    "        s = []\n",
    "    elif c == ' ':\n",
    "        s.append(w)\n",
    "        w = ''\n",
    "    else:\n",
    "        w += c\n",
    "corpus = cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saving-beach",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 22:56:43,886\tBuilding vocab from corpus\n",
      "2021-01-26 22:56:43,927\tDone building vocab from corpus.\n",
      "2021-01-26 22:56:43,934\tVocab has 1918 elements.\n",
      "\n",
      "2021-01-26 22:56:43,940\tFetching cooccurrence list..\n",
      "2021-01-26 22:56:43,960\tBuilding cooccurrence matrix: on line 0\n",
      "2021-01-26 22:56:46,588\tBuilding cooccurrence matrix: on line 1000\n",
      "2021-01-26 22:56:50,150\tBuilding cooccurrence matrix: on line 2000\n",
      "2021-01-26 22:56:51,985\tCooccurrence list fetch complete (22905 pairs).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書の作成\n",
    "vocab = glove.build_vocab(corpus)\n",
    "logger.info(\"Vocab has %i elements.\\n\", len(vocab))\n",
    "logger.info(\"Fetching cooccurrence list..\")\n",
    "cooccur = glove.build_cooccur(\n",
    "\tvocab,\n",
    "\tcorpus,\n",
    "\twindow_size=args.window_size,\n",
    "\tmin_count=args.min_count\n",
    ")\n",
    "logger.info(\"Cooccurrence list fetch complete (%i pairs).\\n\", len(cooccur))\n",
    "id2word = evaluate.make_id2word(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "documentary-stockholm",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 22:56:52,010\tBeginning GloVe training..\n",
      "2021-01-26 22:56:52,199\t\tBeginning iteration 0..\n",
      "2021-01-26 22:56:54,327\t\t\tDone (cost 2110.563916)\n",
      "2021-01-26 22:56:54,330\t\tBeginning iteration 1..\n",
      "2021-01-26 22:56:58,054\t\t\tDone (cost 1613.682383)\n",
      "2021-01-26 22:56:58,056\t\tBeginning iteration 2..\n",
      "2021-01-26 22:57:03,969\t\t\tDone (cost 1409.071523)\n",
      "2021-01-26 22:57:03,972\t\tBeginning iteration 3..\n",
      "2021-01-26 22:57:10,909\t\t\tDone (cost 1279.724101)\n",
      "2021-01-26 22:57:10,913\t\tBeginning iteration 4..\n",
      "2021-01-26 22:57:15,930\t\t\tDone (cost 1178.128112)\n",
      "2021-01-26 22:57:15,933\t\tBeginning iteration 5..\n",
      "2021-01-26 22:57:20,176\t\t\tDone (cost 1075.820170)\n",
      "2021-01-26 22:57:20,178\t\tBeginning iteration 6..\n",
      "2021-01-26 22:57:24,258\t\t\tDone (cost 971.787264)\n",
      "2021-01-26 22:57:24,262\t\tBeginning iteration 7..\n",
      "2021-01-26 22:57:28,651\t\t\tDone (cost 893.479254)\n",
      "2021-01-26 22:57:28,653\t\tBeginning iteration 8..\n",
      "2021-01-26 22:57:32,730\t\t\tDone (cost 842.412218)\n",
      "2021-01-26 22:57:32,732\t\tBeginning iteration 9..\n",
      "2021-01-26 22:57:36,815\t\t\tDone (cost 802.410571)\n",
      "2021-01-26 22:57:36,818\t\tBeginning iteration 10..\n",
      "2021-01-26 22:57:40,889\t\t\tDone (cost 768.411051)\n",
      "2021-01-26 22:57:40,891\t\tBeginning iteration 11..\n",
      "2021-01-26 22:57:44,894\t\t\tDone (cost 740.191038)\n",
      "2021-01-26 22:57:44,896\t\tBeginning iteration 12..\n",
      "2021-01-26 22:57:49,091\t\t\tDone (cost 716.993278)\n",
      "2021-01-26 22:57:49,093\t\tBeginning iteration 13..\n",
      "2021-01-26 22:57:53,252\t\t\tDone (cost 697.145368)\n",
      "2021-01-26 22:57:53,254\t\tBeginning iteration 14..\n",
      "2021-01-26 22:57:59,697\t\t\tDone (cost 679.566222)\n",
      "2021-01-26 22:57:59,701\t\tBeginning iteration 15..\n",
      "2021-01-26 22:58:05,801\t\t\tDone (cost 663.116056)\n",
      "2021-01-26 22:58:05,803\t\tBeginning iteration 16..\n",
      "2021-01-26 22:58:11,609\t\t\tDone (cost 647.669436)\n",
      "2021-01-26 22:58:11,615\t\tBeginning iteration 17..\n",
      "2021-01-26 22:58:15,972\t\t\tDone (cost 632.796533)\n",
      "2021-01-26 22:58:15,976\t\tBeginning iteration 18..\n",
      "2021-01-26 22:58:20,511\t\t\tDone (cost 618.375222)\n",
      "2021-01-26 22:58:20,513\t\tBeginning iteration 19..\n",
      "2021-01-26 22:58:24,769\t\t\tDone (cost 604.464638)\n",
      "2021-01-26 22:58:24,771\t\tBeginning iteration 20..\n",
      "2021-01-26 22:58:29,056\t\t\tDone (cost 591.043254)\n",
      "2021-01-26 22:58:29,059\t\tBeginning iteration 21..\n",
      "2021-01-26 22:58:33,196\t\t\tDone (cost 578.283626)\n",
      "2021-01-26 22:58:33,200\t\tBeginning iteration 22..\n",
      "2021-01-26 22:58:37,685\t\t\tDone (cost 566.001837)\n",
      "2021-01-26 22:58:37,688\t\tBeginning iteration 23..\n",
      "2021-01-26 22:58:42,962\t\t\tDone (cost 554.327557)\n",
      "2021-01-26 22:58:42,965\t\tBeginning iteration 24..\n",
      "2021-01-26 22:58:48,268\t\t\tDone (cost 543.061901)\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "logger.info(\"Beginning GloVe training..\")\n",
    "W = glove.train_glove(\n",
    "\tvocab,\n",
    "\tcooccur,\n",
    "\tvector_size=args.embedding_size,\n",
    "\titerations=args.iterations\n",
    ")\n",
    "W = evaluate.merge_main_context(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tested-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 22:58:49,058\tSaved vectors to suihanki.pkl\n"
     ]
    }
   ],
   "source": [
    "# モデルの保存\n",
    "glove.save_model(W, \"suihanki.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vulnerable-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar word to the 炊飯: No.1 スチーム\n",
      "Similar word to the 炊飯: No.2 器\n",
      "Similar word to the 炊飯: No.3 コース\n",
      "Similar word to the 炊飯: No.4 予約\n",
      "Similar word to the 炊飯: No.5 」\n",
      "Similar word to the 炊飯: No.6 「\n",
      "Similar word to the 炊飯: No.7 ボタン\n",
      "Similar word to the 炊飯: No.8 保温\n",
      "Similar word to the 炊飯: No.9 ｣\n",
      "Similar word to the 炊飯: No.10 本体\n",
      "Similar word to the 炊飯: No.11 時\n",
      "Similar word to the 炊飯: No.12 中\n",
      "Similar word to the 炊飯: No.13 ●\n",
      "Similar word to the 炊飯: No.14 ごはん\n",
      "Similar word to the 炊飯: No.15 洗い\n"
     ]
    }
   ],
   "source": [
    "# '炊飯'に似ている単語を見つける\n",
    "sample = '炊飯'\n",
    "tokens = evaluate.most_similar(W, vocab, id2word, sample)\n",
    "for n, token in enumerate(tokens):\n",
    "\tprint(\"Similar word to the {}: No.{} {}\".format(sample, n+1, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informational-haven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12503674,  0.05938223, -0.10863096, ...,  0.04887136,\n",
       "         0.12237998,  0.17955263],\n",
       "       [-0.10567155, -0.00523037, -0.03543894, ...,  0.05692163,\n",
       "        -0.01669103,  0.03056564],\n",
       "       [-0.07422362,  0.07169773,  0.22255532, ...,  0.11500449,\n",
       "        -0.08311284,  0.05730083],\n",
       "       ...,\n",
       "       [ 0.18337403, -0.07107848,  0.07728845, ...,  0.03935498,\n",
       "        -0.04053991, -0.04611406],\n",
       "       [ 0.01999824,  0.07661286, -0.11690537, ..., -0.04865835,\n",
       "         0.03669333, -0.09124776],\n",
       "       [ 0.18946176,  0.18527365, -0.06452272, ...,  0.20115283,\n",
       "        -0.00851138,  0.07824027]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
